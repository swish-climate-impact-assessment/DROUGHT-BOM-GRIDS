#+TITLE:Drought Bom Grids Overview 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----

* TODOLIST
** TODO need to add metadata
** TODO do an annual average rainfall and compare with the poa_weather data
** TODO start a new project to join drought with nceph study BOUNDARIES_ELECTORATES
* LOAD
Before restoring an SQL dump, all the users who own objects or were granted permissions on objects in the dumped database must already exist. If they do not, the restore will fail to recreate the objects with the original ownership and/or permissions. (Sometimes this is what you want, but usually it is not.)
#+name:prepare ewedb
#+begin_src R :session *shell* :tangle src/prepare ewedb.r :exports none :eval no
###########################################################################
# newnode: prepare ewedb
psql -h 115.146.95.82 -d ewedb -U postgres
CREATE ROLE public_group;
CREATE SCHEMA bom_grids;
grant usage on schema bom_grids to public_group;
CREATE ROLE ivan_hanigan LOGIN PASSWORD 'XXXX';
GRANT ALL ON SCHEMA bom_grids to ivan_hanigan;
\q
# add to pg_hba
reload
select pg_reload_conf();
#+end_src

#+name:dump and restore
#+begin_src sh :session *shell* :tangle src/dump and restore.r :exports none :eval no
###########################################################################
# newnode: dump and restore
/usr/bin/pg_dump --host 130.56.102.41 --port 5432 --username "ivan_hanigan" --role "ivan_hanigan" --no-password  --format plain --encoding UTF8 --verbose --file "/home/ivan_hanigan/projects/DROUGHT-BOM-GRIDS/data/bom_grids.rain_nsw_1890_2008_4.backup" --table "bom_grids.rain_nsw_1890_2008_4" "delphe"


#pg_dump -h 130.56.102.41 -p 5432 -U ivan_hanigan -F t -v -i -f "/home/ivan_hanigan/projects/DROUGHT-BOM-GRIDS/data/bom_grids.rain_nsw_1890_2008_4.backup" -t \"bom_grids\".\"rain_nsw_1890_2008_4\" delphe
cd /home/ivan_hanigan/projects/DROUGHT-BOM-GRIDS/data/
#psql -h 115.146.95.82 -d ewedb -U postgres < "bom_grids.rain_nsw_1890_2008_4.backup"

pg_dump -h 130.56.102.41 -p 5432 -U ivan_hanigan -i -t \"bom_grids\".\"grid_aus\" delphe | psql -h 115.146.94.209 -U postgres ewedb
pg_dump -h 130.56.102.41 -p 5432 -U ivan_hanigan -i -t \"bom_grids\".\"grid_nsw\" delphe | psql -h 115.146.94.209 -U postgres ewedb

in pgadmin
CREATE TABLE bom_grids.rain_aus_1890_2008_4
(
  gid integer NOT NULL,
  timeid integer NOT NULL,
  year integer,
  month integer,
  rain double precision,
  rain6mo double precision,
  pctile double precision,
  rescaledpctile double precision,
  indexbelowthreshold double precision,
  sum double precision,
  count integer,
  CONSTRAINT r_aus_pk PRIMARY KEY (gid , timeid )
)
WITH (
  OIDS=FALSE
);
ALTER TABLE bom_grids.rain_aus_1890_2008_4
  OWNER TO postgres;
GRANT ALL ON TABLE bom_grids.rain_aus_1890_2008_4 TO postgres;
GRANT ALL ON TABLE bom_grids.rain_aus_1890_2008_4 TO public_group;



pg_dump -h 130.56.102.41 -p 5432 -U ivan_hanigan -i -t \"bom_grids\".\"rain_nsw_1890_2008_4\" delphe | psql -h 115.146.95.82 -U postgres ewedb

# test electorates
psql -h 115.146.94.209 -d ewedb -U postgres
CREATE ROLE student_group;
CREATE SCHEMA boundaries_electorates;
grant usage on schema boundaries_electorates to public_group;

pg_dump -h 130.56.102.41 -p 5432 -U ivan_hanigan -i -t \"boundaries_electorates\".\"electorates2009\" delphe | psql -h 115.146.94.209 -U postgres ewedb

#+end_src

* Metadata

*** add metadata using df2ddi bomgrids
#+name:add_ddi
#+begin_src R :session *shell* :tangle src/add_ddi.r :exports none :eval no
  ################################################################
  # name:add_ddi
  setwd('~/projects/DROUGHT-BOM-GRIDS')
  source('~/projects/disentangle/src/df2ddi.r')
  source('~/projects/disentangle/src/connect2postgres.r')
  ewedb <- connect2postgres()
  if(!require(rgdal)) install.packages('rgdal'); require(rgdal)
  if(!require(RJDBC)) install.packages('RJDBC'); require(RJDBC)
  connect2oracle <- function(){
  if(!require(RJDBC)) install.packages('RJDBC'); require(RJDBC)
  drv <- JDBC("oracle.jdbc.driver.OracleDriver",
              '/u01/app/oracle/product/11.2.0/xe/jdbc/lib/ojdbc6.jar')
  p <- readline('enter password: ')
  h <- readline('enter target ipaddres: ')
  d <- readline('enter database name: ')
  ch <- dbConnect(drv,paste("jdbc:oracle:thin:@",h,":1521",sep=''),d,p)
  return(ch)
  }
  ch <- connect2oracle()
  
  #dir.create('metadata')
  #s <- dbGetQuery(ch, "select * from stdydscr where IDNO = 'DROUGHTBOMGRIDS'")
  s <- add_stdydscr(ask=T)
  #write.table(s,'metadata/stdydscr.csv',sep=',',row.names=F)
  
  s$PRODDATESTDY=format(as.Date( substr(s$PRODDATESTDY,1,10),'%Y-%m-%d'),"%d/%b/%Y")
  s$PRODDATEDOC=format(as.Date( substr(s$PRODDATEDOC,1,10),'%Y-%m-%d'),"%d/%b/%Y")
  
  dbSendUpdate(ch,
  # cat(
  paste('
  insert into STDYDSCR (',paste(names(s), sep = '', collapse = ', '),')
  VALUES (',paste("'",paste(gsub("'","",ifelse(is.na(s),'',s)),sep='',collapse="', '"),"'",sep=''),')',sep='')
  )
  
  f <- add_filedscr(fileid = 1, idno = 'DROUGHTBOMGRIDS', ask=T)
  f$FILELOCATION <- 'bom_grids'
  #f$IDNO <- 'DROUGHTBOMGRIDS'
  dbSendUpdate(ch,
  # cat(
  paste('
  insert into FILEDSCR (',paste(names(f), sep = '', collapse = ', '),')
  VALUES (',paste("'",paste(gsub("'","",ifelse(is.na(f),'',f)),sep='',collapse="', '"),"'",sep=''),')',sep='')
  )
  
  #setwd('../data')
  #setwd('abs_sla')
  #test <- readOGR(dsn = 'tassla06.shp', layer = 'tassla06')
  fid <- dbGetQuery(ch,
  #                  cat(
                    paste("select FILEID
                    from filedscr
                    where filelocation = '",f$FILELOCATION,"'
                    and filename = '",f$FILENAME,"'",
                    sep=''))
  
  df <- dbGetQuery(ewedb,
                   'select * from bom_grids.rain_nsw_1890_2008_4 limit 1'
                   )
  df
  d <- add_datadscr(data_frame = df, fileid = fid[1,1], ask=T)
  
  
  for(i in 1:nrow(d)){
  dbSendUpdate(ch,
  #i = 1
  # cat(
  paste('
  insert into DATADSCR (',paste(names(d), sep = '', collapse = ', '),')
  VALUES (',paste("'",paste(gsub("'","",ifelse(is.na(d[i,]),'',d[i,])),sep='',collapse="', '"),"'",sep=''),')',sep='')
  )
  }
  
  
  ###################################################
  # make xml
  s <- dbGetQuery(ch, "select * from stdydscr where idno = 'DROUGHTBOMGRIDS'")
  s
  f <- dbGetQuery(ch, "select * from filedscr where idno = 'DROUGHTBOMGRIDS'")
  f
  for(fi in f){
  d <- dbGetQuery(ch,
                  paste("select * from datadscr where FILEID = ",f$FILEID,
                        sep = '')
                  )
  d
  ddixml <- make_xml(s,f,d)
  }
  out <- dir(pattern='xml')
  file.remove(file.path('/xmldata', out))
  file.copy(out, '/xmldata')
  
#+end_src










*** TODO add metadata using df2ddi electorates, move to elecorate project
#+name:add_ddi
#+begin_src R :session *shell* :tangle src/add_ddi.r :exports none :eval no
  ################################################################
  # name:add_ddi
  source('~/disentangle/src/df2ddi.r')
  source('~/disentangle/src/connect2postgres.r')
  ewedb <- connect2postgres()
  if(!require(rgdal)) install.packages('rgdal'); require(rgdal)
  if(!require(RJDBC)) install.packages('RJDBC'); require(RJDBC)
  drv <- JDBC("oracle.jdbc.driver.OracleDriver",
              '/u01/app/oracle/product/11.2.0/xe/jdbc/lib/ojdbc6.jar')
  p <- readline('enter password: ')
  h <- readline('enter target ipaddres: ')
  d <- readline('enter database name: ')
  ch <- dbConnect(drv,paste("jdbc:oracle:thin:@",h,":1521",sep=''),d,p)
  
  #dir.create('metadata')
  s <- dbGetQuery(ch, "select * from stdydscr where IDNO = 'BOUNDARIES_ELECTORATES'")
  # s <- add_stdydscr(ask=T)
  #write.table(s,'metadata/stdydscr.csv',sep=',',row.names=F)
  
  s$PRODDATESTDY=format(as.Date( substr(s$PRODDATESTDY,1,10),'%Y-%m-%d'),"%d/%b/%Y")
  s$PRODDATEDOC=format(as.Date( substr(s$PRODDATEDOC,1,10),'%Y-%m-%d'),"%d/%b/%Y")
  
  ## dbSendUpdate(ch,
  ## # cat(
  ## paste('
  ## insert into STDYDSCR (',paste(names(s), sep = '', collapse = ', '),')
  ## VALUES (',paste("'",paste(gsub("'","",ifelse(is.na(s),'',s)),sep='',collapse="', '"),"'",sep=''),')',sep='')
  ## )
  
  f <- add_filedscr(fileid = 1, idno = 'BOUNDARIES_ELECTORATES', ask=T)
  f$FILELOCATION <- 'BOUNDARIES_ELECTORATES'
  
  dbSendUpdate(ch,
  # cat(
  paste('
  insert into FILEDSCR (',paste(names(f), sep = '', collapse = ', '),')
  VALUES (',paste("'",paste(gsub("'","",ifelse(is.na(f),'',f)),sep='',collapse="', '"),"'",sep=''),')',sep='')
  )
  f <- dbGetQuery(ch, "select * from filedscr where IDNO = 'BOUNDARIES_ELECTORATES'")
  f
  
  fid <- dbGetQuery(ch,
  #                  cat(
                    paste("select FILEID
                    from filedscr
                    where filelocation = '",f$FILELOCATION,"'
                    and filename = '",f$FILENAME,"'",
                    sep=''))
  
  df <- dbGetQuery(ewedb,
                   'select elect_div, state from boundaries_electorates.electorates2009 limit 1'
                   )
  df[1,]
  df <- readOGR2(hostip = '115.146.94.209', user = 'steven_mceachern',
                   db = 'ewedb', layer =
                   'boundaries_electorates.electorates2009')
  df@data[1:10,]
  d <- add_datadscr(data_frame = df, fileid = fid[1,1], ask=T)
  d
  
  for(i in 1:nrow(d)){
  dbSendUpdate(ch,
  #i = 1
  # cat(
  paste('
  insert into DATADSCR (',paste(names(d), sep = '', collapse = ', '),')
  VALUES (',paste("'",paste(gsub("'","",ifelse(is.na(d[i,]),'',d[i,])),sep='',collapse="', '"),"'",sep=''),')',sep='')
  )
  }
  
  
  ###################################################
  # make xml
  studyID <- 'BOUNDARIES_ELECTORATES'
  s <- dbGetQuery(ch, paste("select * from stdydscr where idno = '",studyID,"'",sep=''))
  s
  f <- dbGetQuery(ch, paste("select * from filedscr where idno = '",studyID,"'",sep=''))
  f
  for(fi in f){
  d <- dbGetQuery(ch,
                  paste("select * from datadscr where FILEID = ",f$FILEID,
                        sep = '')
                  )
  d
  ddixml <- make_xml(s,f,d)
  }
  out <- dir(pattern='xml')
  file.remove(file.path('/xmldata', out))
  file.copy(out, '/xmldata')
  # go to indexer.jsp
  out
  
#+end_src
 

* CLEAN
** TODO Check an electorate
#+name:check
#+begin_src R :session *R* :tangle src/check.r :exports none :eval no
  ###########################################################################
  # newnode: check
    source('~/tools/delphe-project/tools/connect2postgres.r')
    ewedb <- connect2postgres()
    source('~/tools/delphe-project/tools/readOGR2.r')
    require('rgdal')
    source('~/tools/delphe-project/tools/fixGeom.r')
    pwd <-  readline('session password = ')
  # ~/Dropbox/data/drought/HutchinsonIndex/versions/2011-04-23/reports/DroughtDSpatial.png
  
  ## Professor Mike Hutchinson’s Drought Index integrates six-monthly percentiles beyond a threshold by counting the number of months with the threshold exceeded (or summing the rescaled percentiles such that lower values approach -4 and zero is the median value).  The sequence of steps in the algorithm are shown in the figure by 5 panels.  The third panel shows the threshold below which months are integrated by a solid grey polygon.  The fourth and fifth panes show that when the counts/sums reach a threshold then a drought is declared and when the rainfall measure in the third panel rises above that threshold once more the drought has broken.
  
  ## The data in the figure represents the central pixel of the Central West Division of NSW (somewhere close to the town of Parkes) and you can see a few droughts between 1979 and 1983.  Mike questions whether the rain in May to July 1980 was really enough to say the drought had broken.  In discussion with Mike I agreed to explore the spatial and temporal variation in the rescaled percentile
  
  ## I started with a graph inspired by the drought maps at want to reproduce .
  
  ## The result is:
  
  ## So it looks like the drought probably continued right through 1980 until April 1981.
  
  ## I had so much fun I thought I’d share the R code and results here.
  
  ## I use the gislibrary extract function from:
  
  #source('http://alliance.anu.edu.au/access/content/group/4e0f55f1-b540-456a-000a-24730b59fccb/How_to_wiki_files/ClimateDataChallenge/anu_gislibrary_extract.r')
  
  # But am extracting data from NCEPH’s database so you won’t be able to replicate my analysis.
  
  # first I get all the data as one shapefile per month
  setwd('data')
  for(year in 1978:1983){
  #year <- 1978
        for(month in 1:12){
  #month <- 1
        tablename <- paste('Drt',year,month,sep='')
        psql <- paste("select t2.gid,year,month,t1.count,t1.rain,
  case when t1.count >= 5  then 1 else 0 end as threshold,
  rescaledpctile, t2.the_geom
  into ",tablename,"
  from bom_grids.rain_NSW_1890_2008_4 as t1
  join
  (select sds.SD_name,  bom_grids.grid_NSW.gid,
   bom_grids.grid_NSW.the_geom       from (     select elect_div as SD_name,the_geom
                                           as the_geom
                                           from boundaries_electorates.electorates2009     where
                                           elect_div= 'Calare'
                                           ) sds,
   bom_grids.grid_NSW where
   st_intersects(sds.the_geom,
                 bom_grids.grid_NSW.the_geom)
   order by SD_name,bom_grids.grid_NSW.gid) as t2 on t1.gid=t2.gid
  where year=",year," and month = ",month,";",sep='')
  # cat(psql)
  dbSendQuery(ewedb, psql)
  fixGeom('ivan_hanigan',tablename)
  dbSendQuery(ewedb,
  paste("
   INSERT INTO geometry_columns(f_table_catalog, f_table_schema, f_table_name, f_geometry_column, coord_dimension, srid, \"type\")
   SELECT '', 'ivan_hanigan', '",tolower(tablename),"', 'the_geom', ST_CoordDim(the_geom), ST_SRID(the_geom), GeometryType(the_geom)
   FROM ivan_hanigan.",tablename," LIMIT 1
  ", sep ="")
  )
  
        filnam <- paste('Drt',year,month,'.shp',sep='')
  
  
        # extract_pgis(psql=psql,filename=filnam,host='yourHostIP',user='yourUsername',db='yourDatabase', pwd = 'yourPassword')
        outshp <- readOGR2('115.146.94.209', 'ivan_hanigan', 'ewedb',
         tolower(tablename), p = pwd)
        writeOGR(outshp, filnam, gsub('.shp', '', filnam),
        "ESRI Shapefile")
        dbSendQuery(ewedb,paste('drop table ', tablename))
        dbSendQuery(ewedb,paste("delete from geometry_columns
         WHERE f_table_name = '",tolower(tablename),"'", sep = "")
        )
  
       }
  
  }
  
  # then I wrote a function to do the plots (NB the sds spatial object is the Central West Division boundary and is preloaded
  
  plot_drought=function(year,month){
  require('RColorBrewer')
  filnam <- paste('Drt',year,month,'.shp',sep='')
  #d <- load_shp(filnam)
  d <- readOGR(dsn=filnam, layer=gsub('.shp','',filnam))
  stat = 'rscldpc'
  bins <-  c(-4,-3,-2,-1,0,1,2,3,4)
  d@data$bins = cut(d@data[,stat], bins, include.lowest=TRUE)
  x <- seq(-4, 4, 0.1)
  cut(x, bins, include.lowest=TRUE)
  level.labels <- c('[-4,-3]', '(-3,-2]', '(-2,-1]', '(-1,0]', '(0,1]', '(1,2]', '(2,3]', '(3,4]')
  col.vec = brewer.pal(length(bins),"RdYlBu")
  levels(d@data$bins) <- col.vec
  plot(d,
        border = FALSE,
        axes = FALSE,
        las = 1,
        col = as.character(d@data$bins)
        )
  #plot(sds,  add = T)
  }
  
  # start graphing.  Setting up the plot device was challenging but there you go
  
  layout(
  matrix(c(1:13,92,
  14:(14+12),92,
  27:(27+12),92,
  40:(40+12),92,
  53:(53+12),92,
  66:(66+12),92,
  79:(79+12),92
  ),ncol=14, byrow=T)
  )
  
  # just check the plots are going to go in the right order
  layout.show(92)
  par(mar=c(0,0,0,0))
  # first a header column to show months
  plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
  for(mm in toupper(c('j','f','m','a', 'm','j','j','a','s','o','n','d'))){
  plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
  text(1.5,1.5,mm)
  }
  
  # now loop through years and months to plot them
  
  for(j in 1978:1983){
        print(j)
        plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
        text(1.5,1.5,j) #substr(j,3,4))
        for(i in 1:12){
        plot_drought(j,i)
        }
  }
  
  # and finally the legend
  level.labels <- c('[-4,-3]', '(-3,-2]', '(-2,-1]', '(-1,0]', '(0,1]',
  '(1,2]', '(2,3]', '(3,4]')
  bins <-  c(-4,-3,-2,-1,0,1,2,3,4)
  col.vec = brewer.pal(length(bins),"RdYlBu")
  plot(1,1,type = 'n',axes=F)
  legend("top", level.labels, fill=col.vec, title="Legend")
  
#+end_src

** test Check the whole state
#+name:advanceRetreateGraph
#+begin_src R :session *R* :tangle src/advanceRetreateGraph.r :exports none :eval no
    ################################################################
    # name:advanceRetreateGraph
    # this is in my old  files at
    # ~/Dropbox/data/drought/HutchinsonIndex/versions/AdvancRetreatGraph
    # small multiples graph
    source('~/tools/delphe-project/tools/connect2postgres.r')
    ch <- connect2postgres('130.56.102.41','delphe','ivan_hanigan')
    source('~/tools/delphe-project/tools/readOGR2.r')
    require('rgdal')
    source('~/tools/delphe-project/tools/fixGeom.r')
    pwd <-  readline('session password = ')
  
    #################################################################
    # N:\NCEPH_IT\Data Management\projects\9.999 Ivan's PhD\Papers\Suicide and Drought in NSW\data\drought\load_drought_data.r
    # author:
    # ihanigan
    # date:
    # 2010-08-17
    # description:
    # a project of great importance
    #################################################################
  
    # changelog
    Sys.Date()
    # 2010-08-17  make the small multiples plot again but for a longer time period, had to change the extract_pgis arguments to work on nceph machine
  
  
    #source('i:/my dropbox/tools/transformations.r')
    #library(RODBC)
    #ch=odbcConnect('delphe')
    #source('i:/my dropbox/tools/extract_pgis.r')
    library(maptools)
  
  
  
    qc <- dbGetQuery(ch,"select t2.geoid,SD_code,SD_name,year,month,
      cast(year || '-' || month || '-' || 1 as date) as indexdate,
      avg(t1.sum) as avsum,avg(t1.count) as avcount,
      avg(t1.rain) as avrain,
      case when avg(t1.count) >= 5  then avg(t1.count) else 0 end as threshold
    from bom_grids.rain_NSW_1890_2008_4 as t1 join (
            select abs_sd.nswsd91.gid as geoid,abs_sd.nswsd91.SD_code,abs_sd.nswsd91.SD_name,bom_grids.grid_NSW.*
            from abs_sd.nswsd91, bom_grids.grid_NSW
            where st_intersects(abs_sd.nswsd91.the_geom,bom_grids.grid_NSW.the_geom)
            order by SD_code,bom_grids.grid_NSW.gid
    ) as t2
    on t1.gid=t2.gid
    where year>=1970
    group by t2.geoid,SD_code,SD_name,year,month;")
  
    head(qc)
  
    ## sdlist=names(table(qc$sd_name))
    ## sdlist
  
    ## par(mfrow=c(2,6),mar=c(4,3,3,1))
  
    ## for(sdi in sdlist){
    ## #sdi=sdlist[1]
  
    ## with(qc,
    ## plot(indexdate[sd_name==sdi],avcount[sd_name==sdi],type='l',col='red',main=sdi)
    ## )
  
    ## with(qc,
    ## points(indexdate[sd_name==sdi],threshold[sd_name==sdi])
    ## )
    ## }
  
    ## qc=sqlQuery(ch,'select t2.geoid,SD_code,SD_name,year,month,avg(t1.sum) as avsum,avg(t1.count) as avcount,avg(t1.rain) as avrain,
    ## case when avg(t1.count) >= 5  then avg(t1.count) else 0 end as threshold
    ## from bom_grids.rain_NSW_1890_2008_4 as t1 join (
    ##         select abs_sd.nswsd91.gid as geoid,abs_sd.nswsd91.SD_code,abs_sd.nswsd91.SD_name,bom_grids.grid_NSW.*
    ##         from abs_sd.nswsd91, bom_grids.grid_NSW
    ##         where st_intersects(abs_sd.nswsd91.the_geom,bom_grids.grid_NSW.the_geom)
    ##         order by SD_code,bom_grids.grid_NSW.gid
    ## ) as t2
    ## on t1.gid=t2.gid
    ## where year>=1970
    ## group by t2.geoid,SD_code,SD_name,year,month;')
  
    ## # send to local
    ## #local=odbcConnect('ilocal')
    ## #sqlQuery(local,"SET search_path =ivan_hanigan, pg_catalog")
    ## #sqlSave(local,qc,tablename='suicidedroughtnsw19702007_drought')
  
  
    ## # make some qc maps
    ## #extract_pgis(psql='select gid, admin_name, st_simplify(the_geom,0.01) as the_geom FROM spatial.admin00_aus_states where admin_name = \'New South Wales\'','nsw.shp',
    ##   #host='130.56.102.30',user='ivan_hanigan',db='delphe',pgpath='C:\\Program Files\\PostgreSQL\\8.3\\bin\\pgsql2shp')
  
    ## #d=readShapePoly('nsw.shp')
    ## plot(d)
    ## axis(2)
    ## axis(1)
    ## box()
  
    ## #extract_pgis(psql='select * FROM bom_grids.grid_nsw','grid_nsw.shp')
    ## #grd=readShapePoly('grid_nsw.shp')
    ## plot(grd,add=T)
  
    ## # check fields
    ## #sqlQuery(ch,'select * FROM bom_grids.grid_nsw limit 1')
    ## #sqlQuery(ch,'select * FROM bom_grids.rain_NSW_1890_2008_4 limit 1')
  
    ## # get drought data on grid
    ## extract_pgis(psql='select t2.gid,year,month,t1.count,t1.rain,case when t1.count >= 5  then 1 else 0 end as threshold, t2.the_geom from bom_grids.rain_NSW_1890_2008_4 as t1 join bom_grids.grid_NSW as t2 on t1.gid=t2.gid where year=1973 and month = 1 and t1.count >= 5;','197301.shp')
  
    ## #grd=readShapePoly('197301.shp')
    ## plot(grd,add=T,col=grd@data$THRESHOLD)
  
    ## # good.  want to reproduce http://www.dpi.nsw.gov.au/agriculture/emergency/drought/planning/climate/advance-retreat
    ## # get the data to local
    ## cat("\"C:\\PostgreSQL\\8.4\\bin\\pg_dump.exe\" -h 130.56.102.30 -U ivan_hanigan -i -t bom_grids.grid_NSW | \"C:\\PostgreSQL\\8.4\\bin\\psql\" -h localhost postgis")
  
    ## #bom_grids.rain_NSW_1890_2008_4
  
  tassla06 <-
    readOGR2(hostip='115.146.94.209',user='gislibrary',db='pgisdb',
             layer='tassla06')
  plot(tassla06)
    #d=readShapePoly('nsw.shp')
    d <- readOGR2('130.56.102.41','ivan_hanigan','delphe','abs_sd.nswsd01', p = pwd)
    plot(d)
  
    plot_drought=function(year,month){
    extract_pgis(psql=paste('select t2.gid,year,month,t1.count,t1.rain,case when t1.count >= 4  then 1 else 0 end as threshold, t2.the_geom from bom_grids.rain_NSW_1890_2008_4 as t1 join bom_grids.grid_NSW as t2 on t1.gid=t2.gid where year=',year,' and month = ',month,' and t1.count >= 5;',sep=''),'drt.shp',host='130.56.102.30',user='ivan_hanigan',db='delphe',pgpath='C:\\Program Files\\PostgreSQL\\8.3\\bin\\pgsql2shp')
    plot(d)
  
    if(length(dir(pattern='drt.shp'))>0){
            grd=readShapePoly('drt.shp')
            plot(grd,add=T,col=grd@data$THRESHOLD)
            file.remove('drt.shp')
            file.remove('drt.shx')
            file.remove('drt.dbf')
            file.remove('drt.prj')
            }
    }
  
    # newnode THE graph
    windows(height=20,width=6)
    Sys.setenv(R_GSCMD="C:\\gs\\gs8.56\\bin\\gswin32c.exe")
  
    bitmap('droughtAdvRet_19002008.jpg',type='jpeg',res=400,height=20,width=5)
    par(mfrow=c(110,13),mar=c(0,0,0,0))
    plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
  
    for(mm in c('j','f','m','a', 'm','j','j','a','s','o','n','d')){
    plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
    text(1.5,1.5,mm)
    }
  
    for(j in 1900:2008){
    print(j)
             plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
             text(1.5,1.5,j) #substr(j,3,4))
  
             for(i in 1:12){
             plot_drought(j,i)
             }
  
    }
  
    # this is the first one 1972-2008 savePlot('droughtAdvRet.jpg',type=c('jpg'))
    #savePlot('droughtAdvRet_19002008.tiff',type=c('tiff'))
    dev.off()
  
#+end_src

** TODO DroughtSmallMultiples
To do an independent validation of the droughts I Want to reproduce the maps from http://www.dpi.nsw.gov.au/agriculture/emergency/drought/planning/climate/advance-retreat
#+name:testDroughtSmallMultiples
#+begin_src R :session *shell* :tangle src/testDroughtSmallMultiples.R :exports none :eval no
    ################################################################
    # name:testDroughtSmallMultiples
    source('~/tools/delphe-project/tools/connect2postgres.r')
    pwd <-  readline('session password = ')
    ch <- connect2postgres('130.56.102.41','delphe','ivan_hanigan',p=pwd)
    ewedb <- connect2postgres('115.146.94.209','ewedb','ivan_hanigan',p=pwd)
    source('~/tools/delphe-project/tools/readOGR2.r')
    require('rgdal')
    source('~/tools/delphe-project/tools/fixGeom.r')
  
  d <- readOGR2('130.56.102.41','ivan_hanigan','delphe','spatial.admin00_aus_states', p = pwd)
  d <- d[d@data$admin_name == 'New South Wales',]
  plot(d)
    for(year in 1970:1980){
    #year <- 1972
      for(month in 1:12){
      #  month <- 12
      psql=paste('select t2.gid,year,month,t1.count,t1.rain,
       case when t1.count >= 4  then 1 else 0 end as threshold,
       t2.the_geom
       into tempdrt',year,month,'
                 from bom_grids.rain_NSW_1890_2008_4 as t1
                 join bom_grids.grid_NSW as t2
                 on t1.gid=t2.gid
                 where year=',year,' and month = ',month,' and t1.count >= 5;
                 alter table tempdrt',year,month,' add column gid2 serial primary key;
                 ',sep='')
      dbSendQuery(ewedb, psql)
  
      #fixGeom(schema='ivan_hanigan',table=paste('tempdrt',year,month,sep=''))
      dbSendQuery(ewedb,
      #cat(
      paste("
       INSERT INTO geometry_columns(f_table_catalog, f_table_schema, f_table_name, f_geometry_column, coord_dimension, srid, \"type\")
       SELECT '', 'ivan_hanigan', 'tempdrt",year,month,"', 'the_geom', ST_CoordDim(the_geom), ST_SRID(the_geom), GeometryType(the_geom)
       FROM ivan_hanigan.tempdrt",year,month," LIMIT 1;
                  ",sep=""))
      }
    }
  
  
  
 png('droughtAdvRet_19002008.png',res=150,height=20,width=5)
  par(mfrow=c(110,13),mar=c(0,0,0,0))
  plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')

  for(mm in c('j','f','m','a', 'm','j','j','a','s','o','n','d')){
  plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
  text(1.5,1.5,mm)
  }

  for(j in 1972:1973){
  print(j)
  year <- j
           plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
           text(1.5,1.5,j) #substr(j,3,4))

           for(i in 1:12){
             plot(d)
             month <- i
             try(shp <- readOGR2('115.146.94.209','ivan_hanigan','ewedb',paste('tempdrt',year,month,sep=''),
             p = pwd)
             )
             if(exists('shp')) plot(shp,add=T, col='black')
             #plot_drought(j,i)
             rm(shp)
           }

  }

  # this is the first one 1972-2008 savePlot('droughtAdvRet.jpg',type=c('jpg'))
  #savePlot('droughtAdvRet_19002008.tiff',type=c('tiff'))
  dev.off()
  
  
<<<<<<< HEAD
=======
  # going to want to do a straight copy and an enhanced version with
  # continuous levels?  not yet
  dir.create('data')
  setwd('data')
  for(j in 1970:1980){
  #j <- 1970
    print(j)
      year <- j
  
               for(i in 1:12){
  #i <- 1
                 month <- i
                 try(shp <- readOGR2('115.146.94.209','ivan_hanigan','ewedb',paste('tempdrt',year,month,sep=''),
                 p = pwd)
                 )
                 if(exists('shp')) {writeOGR(shp,
                 paste('tempdrt',year,month,'.shp',sep=''), layer =
                 paste('tempdrt',year,month,sep=''), 'ESRI Shapefile')
                                  }
  # plot(shp,add=T, col='black')
                 #plot_drought(j,i)
               }
  
      }
  
    png('../droughtAdvRet_19722008.png',res=150,height=2000,width=1000)
    par(mfrow=c(41,13),mar=c(0,0,0,0))
    plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
  
    for(mm in toupper(c('j','f','m','a', 'm','j','j','a','s','o','n','d'))){
      plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
      text(1.5,1.5,mm)
      }
  
      for(j in 1972:2011){
      print(j)
      year <- j
               plot(0:3,0:3,axes=F,ylab='',xlab='',type='n')
               text(1.5,1.5,j) #substr(j,3,4))
  
               for(i in 1:12){
                 plot(d)
                 month <- i
  
               try(shp <- readOGR(paste('tempdrt',year,month,'.shp',sep=''),paste('tempdrt',year,month,sep='')
               )
               )
               if(exists('shp')) { plot(shp,add=T, col='black')}
               rm(shp)
               }
  
      }
>>>>>>> 8a0d382aeffbcda7bb08a735ffc7253b7ba24afc
  
      # this is the first one 1972-2008 savePlot('droughtAdvRet.jpg',type=c('jpg'))
      #savePlot('droughtAdvRet_19002008.tiff',type=c('tiff'))
      dev.off()
  
    dbSendQuery(ewedb,
                paste('drop table tempdrt',year,month,sep='')
                )
  
#+end_src

This is a cool product by the NSW Dept Primary Industry.

